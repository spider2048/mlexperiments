{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10365497,"sourceType":"datasetVersion","datasetId":6420116}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%pip install uv\n!uv pip install --system evaluate jiwer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:37:57.364204Z","iopub.execute_input":"2025-01-03T21:37:57.364675Z","iopub.status.idle":"2025-01-03T21:38:04.635710Z","shell.execute_reply.started":"2025-01-03T21:37:57.364605Z","shell.execute_reply":"2025-01-03T21:38:04.634832Z"}},"outputs":[{"name":"stdout","text":"Collecting uv\n  Downloading uv-0.5.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nDownloading uv-0.5.14-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.3 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: uv\nSuccessfully installed uv-0.5.14\nNote: you may need to restart the kernel to use updated packages.\n\u001b[2mUsing Python 3.10.12 environment at: /usr\u001b[0m\n\u001b[2K\u001b[2mResolved \u001b[1m35 packages\u001b[0m \u001b[2min 804ms\u001b[0m\u001b[0m                                        \u001b[0m\n\u001b[2K\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)                                                   \n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/82.04 KiB                     \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 16.00 KiB/82.04 KiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 32.00 KiB/82.04 KiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 48.00 KiB/82.04 KiB                   \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 64.00 KiB/82.04 KiB                   \u001b[1A\n\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 64.00 KiB/82.04 KiB                   \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\u001b[2m\u001b[0m\u001b[0m 80.00 KiB/82.04 KiB                   \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)\u001b[2m\u001b[0m\u001b[0m 82.04 KiB/82.04 KiB                   \u001b[2A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/21.47 KiB                     \u001b[1A\n\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m     0 B/2.99 MiB                      \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m\u001b[2m------------------------------\u001b[0m\u001b[0m     0 B/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 14.91 KiB/2.99 MiB                    \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m-----------------------\u001b[2m-------\u001b[0m\u001b[0m 16.00 KiB/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 14.91 KiB/2.99 MiB                    \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 21.47 KiB/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 14.91 KiB/2.99 MiB                    \u001b[2A\n\u001b[2mjiwer     \u001b[0m \u001b[32m------------------------------\u001b[2m\u001b[0m\u001b[0m 21.47 KiB/21.47 KiB\n\u001b[2K\u001b[2A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 30.91 KiB/2.99 MiB                    \u001b[2A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 30.91 KiB/2.99 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 46.91 KiB/2.99 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 62.91 KiB/2.99 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 78.91 KiB/2.99 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 94.91 KiB/2.99 MiB                    \u001b[1A\n\u001b[2K\u001b[1A\u001b[37m‚†ô\u001b[0m \u001b[2mPreparing packages...\u001b[0m (0/3)----\u001b[0m\u001b[0m 110.91 KiB/2.99 MiB                   \u001b[1A\n\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 116ms\u001b[0m\u001b[0m                                                 \u001b[1A\n\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 5ms\u001b[0m\u001b[0m                                 \u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.3\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mjiwer\u001b[0m\u001b[2m==3.0.5\u001b[0m\n \u001b[32m+\u001b[39m \u001b[1mrapidfuzz\u001b[0m\u001b[2m==3.11.0\u001b[0m\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.metrics import *\nfrom sklearn.model_selection import *\nfrom sklearn.preprocessing import *\nfrom PIL import Image\nimport evaluate\nimport os\nfrom tqdm.notebook import tqdm, trange","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:04.637040Z","iopub.execute_input":"2025-01-03T21:38:04.637280Z","iopub.status.idle":"2025-01-03T21:38:18.954590Z","shell.execute_reply.started":"2025-01-03T21:38:04.637261Z","shell.execute_reply":"2025-01-03T21:38:18.953861Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import *\nfrom torch import nn, optim\nfrom transformers import TrOCRProcessor, VisionEncoderDecoderModel, TrOCRConfig\nfrom transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:18.956220Z","iopub.execute_input":"2025-01-03T21:38:18.956871Z","iopub.status.idle":"2025-01-03T21:38:19.743075Z","shell.execute_reply.started":"2025-01-03T21:38:18.956844Z","shell.execute_reply":"2025-01-03T21:38:19.742210Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"processor = TrOCRProcessor.from_pretrained('microsoft/trocr-small-printed', )\nmodel = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-small-printed')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:19.744305Z","iopub.execute_input":"2025-01-03T21:38:19.744541Z","iopub.status.idle":"2025-01-03T21:38:27.179909Z","shell.execute_reply.started":"2025-01-03T21:38:19.744520Z","shell.execute_reply":"2025-01-03T21:38:27.179218Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"248903f6b5464c70a968a23a1bd24318"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/327 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b96b1ea8edba4d51b674221370228744"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"731c14b9173f48d1927be2d218aeee83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/238 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe79174eb684c97816fe4b30a9ce0a2"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/4.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe9f47d731e4f3291df06a049ce78d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/246M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecd4d272fbfa48ecad35b83eeaaaa1c5"}},"metadata":{}},{"name":"stderr","text":"Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a742131cd888460ab5c25ec3c26804a3"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/captchas-qt/generated.xlsx')\ndf.drop(['GENERATED'], axis=1, inplace=True)\ndf.dropna(how='any', inplace=True)\nprint(df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.180823Z","iopub.execute_input":"2025-01-03T21:38:27.181125Z","iopub.status.idle":"2025-01-03T21:38:27.596349Z","shell.execute_reply.started":"2025-01-03T21:38:27.181101Z","shell.execute_reply":"2025-01-03T21:38:27.595479Z"}},"outputs":[{"name":"stdout","text":"(1952, 2)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"          FILE_NAME CAPTCHA_VALUE\n0     captcha_1.png         Hi7qA\n1    captcha_10.png         2aBiC\n2   captcha_100.png         7GksP\n3  captcha_1000.png         t3QgL\n4  captcha_1001.png         b5tGL","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILE_NAME</th>\n      <th>CAPTCHA_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>captcha_1.png</td>\n      <td>Hi7qA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>captcha_10.png</td>\n      <td>2aBiC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>captcha_100.png</td>\n      <td>7GksP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>captcha_1000.png</td>\n      <td>t3QgL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>captcha_1001.png</td>\n      <td>b5tGL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"image_root = Path(\"/kaggle/input/captchas-qt/captchas\")\nimages = sorted(image_root.glob(\"*.png\"))\nlen(images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.597220Z","iopub.execute_input":"2025-01-03T21:38:27.597857Z","iopub.status.idle":"2025-01-03T21:38:27.638427Z","shell.execute_reply.started":"2025-01-03T21:38:27.597823Z","shell.execute_reply":"2025-01-03T21:38:27.637565Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"2000"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"image = Image.open(image_root / 'captcha_1.png')\npixel_values = processor(images=image, return_tensors='pt').pixel_values\npixel_values.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.639384Z","iopub.execute_input":"2025-01-03T21:38:27.639669Z","iopub.status.idle":"2025-01-03T21:38:27.668825Z","shell.execute_reply.started":"2025-01-03T21:38:27.639615Z","shell.execute_reply":"2025-01-03T21:38:27.668036Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 3, 384, 384])"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"class CaptchaDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n\n    def __len__(self):\n        return df.shape[0]\n\n    def __getitem__(self, idx):\n        file_name, text = self.df.iloc[idx, 0], self.df.iloc[idx, 1]\n\n        image = Image.open(image_root / file_name)\n        pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n        labels = processor.tokenizer(text, padding=\"max_length\", max_length=20).input_ids\n        labels = np.asanyarray(labels)\n        labels[labels == processor.tokenizer.pad_token_id] = -100\n        return {\n            \"pixel_values\": pixel_values.squeeze(),\n            \"labels\": torch.from_numpy(labels).long()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.671128Z","iopub.execute_input":"2025-01-03T21:38:27.671384Z","iopub.status.idle":"2025-01-03T21:38:27.676380Z","shell.execute_reply.started":"2025-01-03T21:38:27.671361Z","shell.execute_reply":"2025-01-03T21:38:27.675608Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset = CaptchaDataset(df)\ndataset[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.678360Z","iopub.execute_input":"2025-01-03T21:38:27.678566Z","iopub.status.idle":"2025-01-03T21:38:27.735769Z","shell.execute_reply.started":"2025-01-03T21:38:27.678547Z","shell.execute_reply":"2025-01-03T21:38:27.734855Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'pixel_values': tensor([[[0.5373, 0.5373, 0.5373,  ..., 0.7725, 0.7725, 0.7725],\n          [0.5373, 0.5373, 0.5373,  ..., 0.7725, 0.7725, 0.7725],\n          [0.5373, 0.5373, 0.5373,  ..., 0.7725, 0.7725, 0.7725],\n          ...,\n          [0.7961, 0.7961, 0.7961,  ..., 0.7725, 0.7725, 0.7725],\n          [0.8039, 0.8039, 0.8039,  ..., 0.7725, 0.7725, 0.7725],\n          [0.8039, 0.8039, 0.8039,  ..., 0.7725, 0.7725, 0.7725]],\n \n         [[0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n          [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n          [0.6627, 0.6627, 0.6627,  ..., 0.7725, 0.7725, 0.7725],\n          ...,\n          [0.7804, 0.7804, 0.7804,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7804, 0.7804, 0.7804,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7882, 0.7882, 0.7882,  ..., 0.7725, 0.7725, 0.7725]],\n \n         [[0.7255, 0.7255, 0.7255,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7255, 0.7255, 0.7255,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7255, 0.7255, 0.7255,  ..., 0.7725, 0.7725, 0.7725],\n          ...,\n          [0.7804, 0.7804, 0.7804,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7804, 0.7804, 0.7804,  ..., 0.7725, 0.7725, 0.7725],\n          [0.7804, 0.7804, 0.7804,  ..., 0.7725, 0.7725, 0.7725]]]),\n 'labels': tensor([   0, 3571, 1473, 3581,  370,    2, -100, -100, -100, -100, -100, -100,\n         -100, -100, -100, -100, -100, -100, -100, -100])}"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"total_size = len(dataset)\ntrain_size = int(0.8 * total_size)\ntest_size = total_size - train_size\ntrain_dataset, test_dataset = random_split(dataset, [train_size, test_size])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.736678Z","iopub.execute_input":"2025-01-03T21:38:27.736991Z","iopub.status.idle":"2025-01-03T21:38:27.741905Z","shell.execute_reply.started":"2025-01-03T21:38:27.736960Z","shell.execute_reply":"2025-01-03T21:38:27.741020Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\nmodel.config.pad_token_id = processor.tokenizer.pad_token_id\n\nmodel.config.vocab_size = model.config.decoder.vocab_size\n\nmodel.config.eos_token_id = processor.tokenizer.sep_token_id\nmodel.config.max_new_tokens = 20\nmodel.config.early_stopping = True\n\nmodel.config.length_penalty = 2.0\nmodel.config.num_beams = 2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.742605Z","iopub.execute_input":"2025-01-03T21:38:27.742924Z","iopub.status.idle":"2025-01-03T21:38:27.757206Z","shell.execute_reply.started":"2025-01-03T21:38:27.742877Z","shell.execute_reply":"2025-01-03T21:38:27.756542Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    predict_with_generate=True,\n    evaluation_strategy=\"steps\",\n    per_device_train_batch_size=48,\n    per_device_eval_batch_size=48,\n    fp16=True, \n    output_dir=\"./\",\n    logging_steps=1,\n    save_steps=1000,\n    eval_steps=100,\n    num_train_epochs=10,\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.757930Z","iopub.execute_input":"2025-01-03T21:38:27.758289Z","iopub.status.idle":"2025-01-03T21:38:27.871319Z","shell.execute_reply.started":"2025-01-03T21:38:27.758259Z","shell.execute_reply":"2025-01-03T21:38:27.870436Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"cer_metric = evaluate.load(\"cer\", trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:27.872049Z","iopub.execute_input":"2025-01-03T21:38:27.872294Z","iopub.status.idle":"2025-01-03T21:38:29.577006Z","shell.execute_reply.started":"2025-01-03T21:38:27.872260Z","shell.execute_reply":"2025-01-03T21:38:29.576081Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b6be53fd18f472bbca906b9b537bf4f"}},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels_ids = pred.label_ids\n    pred_ids = pred.predictions\n\n    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n\n    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"cer\": cer}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:38:29.578002Z","iopub.execute_input":"2025-01-03T21:38:29.578308Z","iopub.status.idle":"2025-01-03T21:38:29.583298Z","shell.execute_reply.started":"2025-01-03T21:38:29.578276Z","shell.execute_reply":"2025-01-03T21:38:29.582310Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from transformers import default_data_collator\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# instantiate trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    tokenizer=processor.image_processor,\n    args=training_args,\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    data_collator=default_data_collator,\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:46:17.724533Z","iopub.execute_input":"2025-01-03T21:46:17.724942Z","iopub.status.idle":"2025-01-03T21:54:38.698954Z","shell.execute_reply.started":"2025-01-03T21:46:17.724912Z","shell.execute_reply":"2025-01-03T21:54:38.698241Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [330/330 08:18, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Cer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.051700</td>\n      <td>0.116207</td>\n      <td>0.019437</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.049000</td>\n      <td>0.116383</td>\n      <td>0.023529</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.004000</td>\n      <td>0.093163</td>\n      <td>0.015857</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'early_stopping': True, 'num_beams': 2, 'length_penalty': 2.0}\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=330, training_loss=0.11170911319610295, metrics={'train_runtime': 500.2065, 'train_samples_per_second': 31.207, 'train_steps_per_second': 0.66, 'total_flos': 1.867341370616709e+18, 'train_loss': 0.11170911319610295, 'epoch': 10.0})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"trained_model = VisionEncoderDecoderModel.from_pretrained('checkpoint-330')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:55:19.376512Z","iopub.execute_input":"2025-01-03T21:55:19.376894Z","iopub.status.idle":"2025-01-03T21:55:20.401609Z","shell.execute_reply.started":"2025-01-03T21:55:19.376852Z","shell.execute_reply":"2025-01-03T21:55:20.400711Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"image = Image.open(\"/kaggle/input/captchas-qt/captchas/captcha_101.png\").convert(\"RGB\")\nimage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:55:22.512623Z","iopub.execute_input":"2025-01-03T21:55:22.513028Z","iopub.status.idle":"2025-01-03T21:55:22.525095Z","shell.execute_reply.started":"2025-01-03T21:55:22.512997Z","shell.execute_reply":"2025-01-03T21:55:22.524277Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<PIL.Image.Image image mode=RGB size=120x40>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAHgAAAAoCAIAAAC6iKlyAAAET0lEQVR4Ae2YWU8qMRiGRUZF8Yi7uILGqHihiX/An+C9P8Z/5xUkXrlrjOC+C7gc1/PEJs1k5MBsdCB0rkqn/do+ffv2G0Jra2tN+qk+AePz87P6o+gRmjRoRSLQoFWB/vj4UDRUYw+jFa1o/zVoDVoRAUXDaEXXFeh0Ov36+mqZ8szMzNDQkKWyYX/6o+ijo6NisWiBODg42N/fb6ms+PP7+/v+/n5/f//y8pKPqY6OjrGxMfaspaWlYt9abmD4kt6trKyYF7m+vn53d9fZ2ekiOHuWyWSIJsg+Pj7e3NzAOhqNmoeou7I/ijYvGzS5XC6ZTHZ1dTn9vr+9vcWF+vr65ufnBwYGQqHQ8/PzxcVFOBx2Gso8pVoo+w96a2sLLiMjIyzPKZ29vT3gzs7Owvrr64sIbW1tiUTCRahagGueg8+gHx4e8NZYLAYpp5SZFoZjGEZPT4+LvuZV1WDZH4+WC8M03t7epqam0KOQpHwlCxj3+/t7a2srwheVYBU13IQ8/PxfXxmk7gp+Kvrp6en6+ho5k2yUkeTJycnm5iaJBPsheO3u7p6dnS0uLtL36uqK26+3t7fuUJafsG+gUSKASPIWFhbKUGY2bEN7ezu48XFSCxpT7u7uJq8YHx/Hecjt2AMMBL8mPeeGJB/HUsqv5PdbpoSVMSsOWXNzM5kiQweVvfgGmrNPevDn5ykPGscYHh4mjQMBuTa96IuEwUpGODc3t7Ozs7GxQTNq8BCshm2gbEaJm3Nzsh9EkPU0Pj4+JiyHA2siH9/e3iZvgThtCHh4eLi8vCzbqyz4BhrJoGUx9fKgaSNA4xIQRM7oGtCiF+CQHk4CJmrQPjIkuCUmXUBPX25dyQvlciCEZmkPYh4yRXG74mziI0i2V1kwArl2AMc3CIZ+fn6O28TjcZxBzgTQ09PTFgryragn7UP+nIaXlxfKohKUkB0dHRVHIRKJAB1RE5CN4bBNTExY4lhGqd5PQ1791RujZGTggglJcq6xZhfTQMucCR4+jsQQBOQE8KEkonG1plIpNpINwH+Qc6FQWFpaKjmfalcGBhqt4QmAhjjadLFOPh0PDg7Ah1MjYbwC6FQCmhNDwHw+z2cqFyka//vzYEcudtTF3H534cg6vs1/R3Faw+2HxFAfRNCjuznQC4inp6fQZM9wIaaBzLkGxXwYgiuXHEZehu6yF6erK9k+GEWTMJAAIC6cmpvKtcr4Os9ms2QggOb+xIg5HzIaVy72zVtyRCrxaBJK+bYkjupVBgMaU8ZAkSSU5VXmYpF0Jw6KJtfGi8ENTRkHpnDnkTUBFoIBTTLH48uyJycn+RuL84EdUQ5KsBXXgqoC8OiK07LfgIsOyiR5SJuy/Y6KW4ZWV1cVD9mYwwVjHQ3IWoNWtOkatAatiICiYeo+61DEyfMw2jo8I7QXQIO2x8lzKw3aM0J7ATRoe5w8t9KgPSO0F0CDtsfJc6t/9y03iZgKUakAAAAASUVORK5CYII=\n","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAoAHgDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwCl9q96PtXvWN9q96PtXvQBs/avej7V71iST+ZG6b2TcCNynke496xYzNFrUMMWoXkqRqZJhK4I9AOAKAO1+1e9H2r3rG+1Y71HNfrBBJKxyEUsQPYZoA3ftXvR9q965G1uNUuVhu2vY443w/kCIEbT23dc4rV+1e9AGz9q96PtXvWN9q96PtXvQBs/avej7V71jfavej7V70AbP2r3o+1e9Y32r3o+1e9AGz9q96KxvtXvRQBl5k9KMyelaX2X2o+y+1AGbmT0qGGAwySyLuLStuYn9B9K2PsvtR9l9qAMmaMzwvFIMo4INZdks11cBJxuS0UxHPRmPGfy/nXUtaBlKsuQRgimQ6dFbx+XDEqJ1woxQBhRWN1AUSK8kECkYjKgnHpnrip72S5js5JIeHQbumcgdRW19l9qPsoPagDn5LySSSzSBv8AXfOTjPyAZP8ASs++u54ryUm8YBWAVI5FBH/ASOa6Cw0EWU7yGUyDbsjUrjYuSce//wBarpsImcOYkLjoxUZoAoZk9KMyelaX2X2o+y+1AGbmT0ozJ6VpfZfaj7L7UAZuZPSitL7L7UUAbP2b2o+ze1FFAB9m9qPs3tRRQAfZvaj7N7UUUAH2b2o+ze1FFAB9m9qPs3tRRQAfZvaj7N7UUUAH2b2o+ze1FFAB9m9qKKKAP//Z\n"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"def rec(image):\n    pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values.to('cuda')\n    generated_ids = model.generate(pixel_values)\n    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n    return generated_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:55:23.592309Z","iopub.execute_input":"2025-01-03T21:55:23.592703Z","iopub.status.idle":"2025-01-03T21:55:23.597350Z","shell.execute_reply.started":"2025-01-03T21:55:23.592655Z","shell.execute_reply":"2025-01-03T21:55:23.596362Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"rec(image)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:55:29.060442Z","iopub.execute_input":"2025-01-03T21:55:29.060760Z","iopub.status.idle":"2025-01-03T21:55:29.173879Z","shell.execute_reply.started":"2025-01-03T21:55:29.060733Z","shell.execute_reply":"2025-01-03T21:55:29.172890Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'7yCVs'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"values = []\n\nfor idx in trange(df.shape[0]):\n    fname = df.iloc[idx, 0]\n    value = rec(Image.open(image_root / fname))\n    values.append(value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:55:35.738123Z","iopub.execute_input":"2025-01-03T21:55:35.738428Z","iopub.status.idle":"2025-01-03T21:58:55.902739Z","shell.execute_reply.started":"2025-01-03T21:55:35.738404Z","shell.execute_reply":"2025-01-03T21:58:55.901724Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1952 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5ff988927e146d7aaed64ed309ddf36"}},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"df['GENERATED_VALUE'] = values\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:58:58.659238Z","iopub.execute_input":"2025-01-03T21:58:58.659577Z","iopub.status.idle":"2025-01-03T21:58:58.669830Z","shell.execute_reply.started":"2025-01-03T21:58:58.659544Z","shell.execute_reply":"2025-01-03T21:58:58.668964Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"          FILE_NAME CAPTCHA_VALUE GENERATED_VALUE\n0     captcha_1.png         Hi7qA           Hi7qA\n1    captcha_10.png         2aBiC           2aBiC\n2   captcha_100.png         7GksP           7GksP\n3  captcha_1000.png         t3QgL           t3QgL\n4  captcha_1001.png         b5tGL           b5tGL","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILE_NAME</th>\n      <th>CAPTCHA_VALUE</th>\n      <th>GENERATED_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>captcha_1.png</td>\n      <td>Hi7qA</td>\n      <td>Hi7qA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>captcha_10.png</td>\n      <td>2aBiC</td>\n      <td>2aBiC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>captcha_100.png</td>\n      <td>7GksP</td>\n      <td>7GksP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>captcha_1000.png</td>\n      <td>t3QgL</td>\n      <td>t3QgL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>captcha_1001.png</td>\n      <td>b5tGL</td>\n      <td>b5tGL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"invalid = df[(df['CAPTCHA_VALUE'] != df['GENERATED_VALUE'])]\nprint(len(invalid))\ninvalid","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:59:01.393297Z","iopub.execute_input":"2025-01-03T21:59:01.393626Z","iopub.status.idle":"2025-01-03T21:59:01.407701Z","shell.execute_reply.started":"2025-01-03T21:59:01.393596Z","shell.execute_reply":"2025-01-03T21:59:01.406718Z"}},"outputs":[{"name":"stdout","text":"39\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"             FILE_NAME CAPTCHA_VALUE GENERATED_VALUE\n90     captcha_108.png         S7jKr           S7jkr\n137   captcha_1121.png         E6pZi           E6pZj\n169   captcha_1150.png         UdU6n           UdUGn\n203   captcha_1181.png         m9XyJ           m9XYJ\n209   captcha_1187.png         bAq5x           bAq5X\n217   captcha_1194.png         4QBKi           4QBki\n297   captcha_1266.png         LtJc2           LtJC2\n343   captcha_1307.png         1iGcH           1iGct\n401    captcha_136.png         5jiCE            5jCE\n414   captcha_1371.png         kuc5H           Xuc5H\n468    captcha_142.png         WU3di           Wu3di\n514   captcha_1461.png         9HhAm            9hhm\n728   captcha_1654.png         Rqq5B          Rqqq5B\n851   captcha_1765.png         E4LyQ           E4Lyq\n856    captcha_177.png         GuT1f          GuiT1f\n962   captcha_1865.png         W6zZc           W6zZo\n977   captcha_1879.png         z1CdK           z1Cdk\n989    captcha_189.png         6iZuW           6fZwU\n1037  captcha_1932.png         H1cCt           H1cCl\n1072  captcha_1964.png         k7DQc           k7DQe\n1078   captcha_197.png         PQdg6           PQdG6\n1113   captcha_200.png         JFpw8           JFpws\n1124    captcha_21.png         Yxe8U           Yze8U\n1147   captcha_230.png         Gy7qc           Gy7qC\n1167   captcha_249.png         H4uGt           H4uGY\n1183   captcha_263.png         3HaqD          3 HaqD\n1187   captcha_267.png         MTyq4            MTV4\n1249   captcha_322.png         s1Zvh           s1ZVh\n1265   captcha_337.png         dVs2c           dVs2C\n1409   captcha_467.png         Q6uWt            Q6ut\n1451   captcha_504.png         aGTs2           aGTS2\n1452   captcha_505.png         7ZzkU           7ZzKU\n1458   captcha_510.png         iBj7h           iBJ7h\n1594   captcha_633.png         WdjW2           wDjW2\n1602   captcha_640.png         DWj3u           DWJ3u\n1621   captcha_658.png         6ZabA           6ZAbA\n1637   captcha_672.png         7MEph          7MEphh\n1690    captcha_72.png         Sz4eW           SZ4eW\n1742   captcha_767.png         WBeJ5           WBwJ5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FILE_NAME</th>\n      <th>CAPTCHA_VALUE</th>\n      <th>GENERATED_VALUE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>90</th>\n      <td>captcha_108.png</td>\n      <td>S7jKr</td>\n      <td>S7jkr</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>captcha_1121.png</td>\n      <td>E6pZi</td>\n      <td>E6pZj</td>\n    </tr>\n    <tr>\n      <th>169</th>\n      <td>captcha_1150.png</td>\n      <td>UdU6n</td>\n      <td>UdUGn</td>\n    </tr>\n    <tr>\n      <th>203</th>\n      <td>captcha_1181.png</td>\n      <td>m9XyJ</td>\n      <td>m9XYJ</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>captcha_1187.png</td>\n      <td>bAq5x</td>\n      <td>bAq5X</td>\n    </tr>\n    <tr>\n      <th>217</th>\n      <td>captcha_1194.png</td>\n      <td>4QBKi</td>\n      <td>4QBki</td>\n    </tr>\n    <tr>\n      <th>297</th>\n      <td>captcha_1266.png</td>\n      <td>LtJc2</td>\n      <td>LtJC2</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>captcha_1307.png</td>\n      <td>1iGcH</td>\n      <td>1iGct</td>\n    </tr>\n    <tr>\n      <th>401</th>\n      <td>captcha_136.png</td>\n      <td>5jiCE</td>\n      <td>5jCE</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>captcha_1371.png</td>\n      <td>kuc5H</td>\n      <td>Xuc5H</td>\n    </tr>\n    <tr>\n      <th>468</th>\n      <td>captcha_142.png</td>\n      <td>WU3di</td>\n      <td>Wu3di</td>\n    </tr>\n    <tr>\n      <th>514</th>\n      <td>captcha_1461.png</td>\n      <td>9HhAm</td>\n      <td>9hhm</td>\n    </tr>\n    <tr>\n      <th>728</th>\n      <td>captcha_1654.png</td>\n      <td>Rqq5B</td>\n      <td>Rqqq5B</td>\n    </tr>\n    <tr>\n      <th>851</th>\n      <td>captcha_1765.png</td>\n      <td>E4LyQ</td>\n      <td>E4Lyq</td>\n    </tr>\n    <tr>\n      <th>856</th>\n      <td>captcha_177.png</td>\n      <td>GuT1f</td>\n      <td>GuiT1f</td>\n    </tr>\n    <tr>\n      <th>962</th>\n      <td>captcha_1865.png</td>\n      <td>W6zZc</td>\n      <td>W6zZo</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>captcha_1879.png</td>\n      <td>z1CdK</td>\n      <td>z1Cdk</td>\n    </tr>\n    <tr>\n      <th>989</th>\n      <td>captcha_189.png</td>\n      <td>6iZuW</td>\n      <td>6fZwU</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>captcha_1932.png</td>\n      <td>H1cCt</td>\n      <td>H1cCl</td>\n    </tr>\n    <tr>\n      <th>1072</th>\n      <td>captcha_1964.png</td>\n      <td>k7DQc</td>\n      <td>k7DQe</td>\n    </tr>\n    <tr>\n      <th>1078</th>\n      <td>captcha_197.png</td>\n      <td>PQdg6</td>\n      <td>PQdG6</td>\n    </tr>\n    <tr>\n      <th>1113</th>\n      <td>captcha_200.png</td>\n      <td>JFpw8</td>\n      <td>JFpws</td>\n    </tr>\n    <tr>\n      <th>1124</th>\n      <td>captcha_21.png</td>\n      <td>Yxe8U</td>\n      <td>Yze8U</td>\n    </tr>\n    <tr>\n      <th>1147</th>\n      <td>captcha_230.png</td>\n      <td>Gy7qc</td>\n      <td>Gy7qC</td>\n    </tr>\n    <tr>\n      <th>1167</th>\n      <td>captcha_249.png</td>\n      <td>H4uGt</td>\n      <td>H4uGY</td>\n    </tr>\n    <tr>\n      <th>1183</th>\n      <td>captcha_263.png</td>\n      <td>3HaqD</td>\n      <td>3 HaqD</td>\n    </tr>\n    <tr>\n      <th>1187</th>\n      <td>captcha_267.png</td>\n      <td>MTyq4</td>\n      <td>MTV4</td>\n    </tr>\n    <tr>\n      <th>1249</th>\n      <td>captcha_322.png</td>\n      <td>s1Zvh</td>\n      <td>s1ZVh</td>\n    </tr>\n    <tr>\n      <th>1265</th>\n      <td>captcha_337.png</td>\n      <td>dVs2c</td>\n      <td>dVs2C</td>\n    </tr>\n    <tr>\n      <th>1409</th>\n      <td>captcha_467.png</td>\n      <td>Q6uWt</td>\n      <td>Q6ut</td>\n    </tr>\n    <tr>\n      <th>1451</th>\n      <td>captcha_504.png</td>\n      <td>aGTs2</td>\n      <td>aGTS2</td>\n    </tr>\n    <tr>\n      <th>1452</th>\n      <td>captcha_505.png</td>\n      <td>7ZzkU</td>\n      <td>7ZzKU</td>\n    </tr>\n    <tr>\n      <th>1458</th>\n      <td>captcha_510.png</td>\n      <td>iBj7h</td>\n      <td>iBJ7h</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>captcha_633.png</td>\n      <td>WdjW2</td>\n      <td>wDjW2</td>\n    </tr>\n    <tr>\n      <th>1602</th>\n      <td>captcha_640.png</td>\n      <td>DWj3u</td>\n      <td>DWJ3u</td>\n    </tr>\n    <tr>\n      <th>1621</th>\n      <td>captcha_658.png</td>\n      <td>6ZabA</td>\n      <td>6ZAbA</td>\n    </tr>\n    <tr>\n      <th>1637</th>\n      <td>captcha_672.png</td>\n      <td>7MEph</td>\n      <td>7MEphh</td>\n    </tr>\n    <tr>\n      <th>1690</th>\n      <td>captcha_72.png</td>\n      <td>Sz4eW</td>\n      <td>SZ4eW</td>\n    </tr>\n    <tr>\n      <th>1742</th>\n      <td>captcha_767.png</td>\n      <td>WBeJ5</td>\n      <td>WBwJ5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"df.to_excel(\"new_captcha_values.xlsx\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T21:59:02.704669Z","iopub.execute_input":"2025-01-03T21:59:02.704981Z","iopub.status.idle":"2025-01-03T21:59:02.913260Z","shell.execute_reply.started":"2025-01-03T21:59:02.704956Z","shell.execute_reply":"2025-01-03T21:59:02.912549Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"!du -sh checkpoint-330/*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:00:23.756666Z","iopub.execute_input":"2025-01-03T22:00:23.757056Z","iopub.status.idle":"2025-01-03T22:00:23.926036Z","shell.execute_reply.started":"2025-01-03T22:00:23.757022Z","shell.execute_reply":"2025-01-03T22:00:23.924889Z"}},"outputs":[{"name":"stdout","text":"8.0K\tcheckpoint-330/config.json\n4.0K\tcheckpoint-330/generation_config.json\n236M\tcheckpoint-330/model.safetensors\n470M\tcheckpoint-330/optimizer.pt\n4.0K\tcheckpoint-330/preprocessor_config.json\n16K\tcheckpoint-330/rng_state.pth\n4.0K\tcheckpoint-330/scheduler.pt\n60K\tcheckpoint-330/trainer_state.json\n8.0K\tcheckpoint-330/training_args.bin\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"(df['CAPTCHA_VALUE'] == df['GENERATED_VALUE']).mean()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:03:26.417049Z","iopub.execute_input":"2025-01-03T22:03:26.417439Z","iopub.status.idle":"2025-01-03T22:03:26.425555Z","shell.execute_reply.started":"2025-01-03T22:03:26.417406Z","shell.execute_reply":"2025-01-03T22:03:26.424735Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.9800204918032787"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"I = torch.randn(1, 3, 384, 384)\nO = model.cpu().generate(I)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:08:24.335068Z","iopub.execute_input":"2025-01-03T22:08:24.335490Z","iopub.status.idle":"2025-01-03T22:08:25.882676Z","shell.execute_reply.started":"2025-01-03T22:08:24.335452Z","shell.execute_reply":"2025-01-03T22:08:25.881730Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"inputs = processor(image, return_tensors=\"pt\")\ninput_ids = inputs.pixel_values","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:11:43.744047Z","iopub.execute_input":"2025-01-03T22:11:43.744373Z","iopub.status.idle":"2025-01-03T22:11:43.756596Z","shell.execute_reply.started":"2025-01-03T22:11:43.744349Z","shell.execute_reply":"2025-01-03T22:11:43.755732Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-03T22:15:30.744162Z","iopub.execute_input":"2025-01-03T22:15:30.744628Z","iopub.status.idle":"2025-01-03T22:15:30.753807Z","shell.execute_reply.started":"2025-01-03T22:15:30.744583Z","shell.execute_reply":"2025-01-03T22:15:30.752930Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"VisionEncoderDecoderModel(\n  (encoder): DeiTModel(\n    (embeddings): DeiTEmbeddings(\n      (patch_embeddings): DeiTPatchEmbeddings(\n        (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): DeiTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x DeiTLayer(\n          (attention): DeiTAttention(\n            (attention): DeiTSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): DeiTSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): DeiTIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DeiTOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n    (pooler): DeiTPooler(\n      (dense): Linear(in_features=384, out_features=384, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): TrOCRForCausalLM(\n    (model): TrOCRDecoderWrapper(\n      (decoder): TrOCRDecoder(\n        (embed_tokens): TrOCRScaledWordEmbedding(64044, 256, padding_idx=1)\n        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256)\n        (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (layers): ModuleList(\n          (0-5): 6 x TrOCRDecoderLayer(\n            (self_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (activation_fn): ReLU()\n            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n      )\n    )\n    (output_projection): Linear(in_features=256, out_features=64044, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":51}]}